
<!-- This document was automatically generated with bibtex2html 1.98
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     /usr/bin/bibtex2html -o literature -nodoc -q literature.bib  -->


<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="Semedo_acmmm_2020_temporal_adaptive_triplet_loss">1</a>]
</td>
<td class="bibtexitem">
David Semedo and Jo&atilde;o Magalh&atilde;es.
 Adaptive temporal triplet-loss for cross-modal embedding learning.
 In <em>Proceedings of the 28th ACM International Conference on
  Multimedia</em>, MM '20, page 1152â€“1161, New York, NY, USA, 2020. Association
  for Computing Machinery.
[&nbsp;<a href="literature_bib.html#Semedo_acmmm_2020_temporal_adaptive_triplet_loss">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3394171.3413540">DOI</a>&nbsp;| 
<a href="https://doi.org/10.1145/3394171.3413540">http</a>&nbsp;]
<blockquote><font size="-1">
There are many domains where the temporal dimension is critical to unveil how different modalities, such as images and texts, are correlated. Notably, in the social media domain, information is constantly evolving over time according to the events that take place in the real world. In this work, we seek for highly expressive loss functions that allow the encoding of data temporal traits into cross-modal embedding spaces. To achieve this goal, we propose to steer the learning procedure of such embedding through a set of adaptively enforced temporal constraints. In particular, we propose a new formulation of the triplet loss function, where the traditional static margin is superseded by a novel temporally adaptive maximum margin function. This novel redesign of the static margin formulation, allows the embedding to effectively capture not only the semantic correlations across data modalities, but also data's fine-grained temporal correlations. Our experiments confirm the effectiveness of our model in structuring different modalities, while organizing data according to temporal correlations. Moreover, we experimentally highlight how can these embeddings be used for multimedia understanding.
</font></blockquote>
<p><blockquote><font size="-1">
Keywords: temporal cross-modal embeddings, adaptive temporal triplet-loss, cross-modal embeddings, multimedia-understanding
</font></blockquote>

</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
